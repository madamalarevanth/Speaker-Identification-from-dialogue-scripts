{"cells":[{"cell_type":"markdown","metadata":{"id":"t5xM8GyfIQ7d"},"source":["# WebScarping "]},{"cell_type":"markdown","source":["Modified Original Script From https://github.com/shamafarabi/NLP-Predict-Cast-Member-of-the-TV-Show-Friends"],"metadata":{"id":"4mtVw42pIVLZ"}},{"cell_type":"markdown","metadata":{"id":"4Z0TuiptIQ7f"},"source":[" # Import Packages"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IrUX67QWIQ7f"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from urllib.request import urlopen\n","from bs4 import BeautifulSoup\n","from collections import defaultdict\n","import re\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"s8E9df5TIQ7g"},"outputs":[],"source":["url = \"https://fangj.github.io/friends/\"\n","html = urlopen(url)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DpWodWaSIQ7g","outputId":"6e966725-aeab-401f-e7d0-c99ac4638a45"},"outputs":[{"data":{"text/plain":["bs4.BeautifulSoup"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["soup = BeautifulSoup(html, 'html.parser')\n","type(soup)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjfthgS0IQ7h"},"outputs":[],"source":["# Print out the text\n","text = soup.get_text()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iiZmtRz5IQ7h"},"outputs":[],"source":["season_list = text.split('\\n')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ec3O8lQIIQ7h","outputId":"2144954e-5c15-4bd8-b72b-4a5ffa2cb31d"},"outputs":[{"name":"stdout","output_type":"stream","text":["['1001 Joey and Rachel Kiss', '1002 Ross Is Fine', \"1003 Ross's Tan\", '1004 The Cake', \"1005  Rachel's Sister Babysits\", \"1006  Ross's Grant\", '1007 The Home Study', '1008 The Late Thanksgiving', '1009 The Birth Mother', '1010 Chandler Gets Caught', '1011 The Stripper Cries', \"1012  Phoebe's Wedding\", '1013 Joey Speaks French', '1014 Princess Consuela', '1015 Estelle Dies', \"1016 Rachel's Going Away Party\", '1017-1018 The Last One, Part I & II', '', '', '']\n"]}],"source":["print(season_list[-20:])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KFUO6t1zIQ7h"},"outputs":[],"source":["episodes =[l for l in season_list if l[0:3].isdigit()];\n","episode_numbers, episode_names = [], []\n","for l in episodes:\n","    matches = re.match(r'^(?:(\\d+-\\d+)|(\\d+))\\s(.+)$', l)\n","    if matches.group(1):\n","        episode_numbers.append(matches.group(1))\n","    else:\n","        episode_numbers.append(matches.group(2))\n","    episode_names.append(matches.group(3).strip())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zZXcRGzaIQ7h","outputId":"e6818d09-36a8-439e-a957-4c1653db97df"},"outputs":[{"name":"stdout","output_type":"stream","text":["['101', '102', '103', '104', '105', '106', '107', '108', '109', '110', '111', '112', '113', '114', '115', '116', '117', '118', '119', '120', '121', '122', '123', '124', '201', '202', '203', '204', '205', '206', '207', '208', '209', '210', '211', '212-213', '214', '215', '216', '217', '218', '219', '220', '221', '222', '223', '224', '301', '302', '303', '304', '305', '306', '307', '308', '309', '310', '311', '312', '313', '314', '315', '316', '317', '318', '319', '320', '321', '322', '323', '324', '325', '401', '402', '403', '404', '405', '406', '407', '408', '409', '410', '411', '412', '413', '414', '415', '416', '417', '418', '419', '420', '421', '422', '423', '501', '502', '503', '504', '505', '506', '507', '508', '509', '510', '511', '512', '513', '514', '515', '516', '517', '518', '519', '520', '521', '522', '523', '601', '602', '603', '604', '605', '606', '607', '608', '609', '610', '611', '612', '613', '614', '615-616', '617', '618', '619', '620', '621', '622', '623', '624', '701', '702', '703', '704', '705', '706', '707', '708', '709', '710', '711', '712', '713', '714', '715', '716', '717', '718', '719', '720', '721', '722', '723', '724', '801', '802', '803', '804', '805', '806', '807', '808', '809', '810', '811', '812', '813', '814', '815', '816', '817', '818', '819', '820', '821', '822', '823', '901', '902', '903', '904', '905', '906', '907', '908', '909', '910', '911', '912', '913', '914', '915', '916', '917', '918', '919', '920', '921', '922', '923-924', '1001', '1002', '1003', '1004', '1005', '1006', '1007', '1008', '1009', '1010', '1011', '1012', '1013', '1014', '1015', '1016', '1017-1018']\n"]}],"source":["print(episode_numbers)"]},{"cell_type":"markdown","metadata":{"id":"3ZryAicgIQ7i"},"source":["Except for season 724, Most common url formats are addressed as 3 digit or 7 digit format. we will do try and except for that one episode so that we can continue the loop"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"hG3tl_1KIQ7i"},"outputs":[],"source":["all_transcripts =   {'Episodes':[], 'Episode_Names':[],'Characters': [],'Lines': []} \n","for episode in episode_numbers:\n","    try:\n","        # to extract url that has 3 digit as the number of the episode (e.g. 101)\n","        episode_url = episode\n","        if len(episode_url) in [3, 4]:\n","            if len(episode) == 3:\n","                episode_url = '0' + episode_url\n","        else:\n","            # to extract url that has 7 digit as the number of the episode (e.g. 212-213)\n","            if len(episode_url) == 7:\n","                episode_url = '-'.join(map(lambda x: '0' + x, episode_url.split('-')))\n","        url = 'https://fangj.github.io/friends/season/{0}.html'.format(episode_url)\n","        html = urlopen(url)\n","    # only one  url  of all the episodes had a diferent format than the above two in the url, ignore it\n","    except Exception as e:\n","        continue\n","            \n","    #parse the html\n","    soup = BeautifulSoup(html, 'html.parser')\n","    #identify html tags and attributes associated with actors and their dialogues in the script\n","    transcripts = soup.find_all('p')\n","\n","     # Print text only, and further filter tags to fin Charcater: Lines\n","    pattern = '^\\w+[:]'   \n","    transcripts_text_only = [p.text for p in transcripts if re.search(pattern,p.text) ]\n","\n","    #split Characters and Lines\n","    Characters_this_episode = [l.split(\":\") [0] for l in transcripts_text_only]\n","    Lines_this_episode = [l.split(\":\") [1] for l in transcripts_text_only]\n","    \n","    #store episode number and episode name for each line\n","    Episode = [episode]*len(Characters_this_episode) \n","    Episode_Name = [episode_names[episode_numbers.index(episode)]]*len(Characters_this_episode)\n","    \n","    all_transcripts['Episodes'].append(Episode)\n","    all_transcripts['Episode_Names'].append(Episode_Name)\n","    all_transcripts['Characters'].append(Characters_this_episode)\n","    all_transcripts['Lines'].append(Lines_this_episode)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"waUIfUuVIQ7j","outputId":"90b08a7e-f1d4-4935-e410-2ae0dc63235f"},"outputs":[{"data":{"text/plain":["list"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["type(all_transcripts['Episodes'])"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":false,"id":"bzaVSCK8IQ7k"},"outputs":[],"source":["#Each dictionary has list of lists as values. Flatten them so that each key has a single list\n","import itertools\n","all_transcripts['Episodes']= list (itertools.chain.from_iterable(  all_transcripts['Episodes']))\n","all_transcripts['Episode_Names']= list (itertools.chain.from_iterable(  all_transcripts['Episode_Names']))\n","all_transcripts['Characters']= list (itertools.chain.from_iterable(  all_transcripts['Characters']))\n","all_transcripts['Lines']= list (itertools.chain.from_iterable(  all_transcripts['Lines']))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1ULZcOGbIQ7k","outputId":"61bfe170-3867-4fe1-d33a-1ce1cf4cb1df"},"outputs":[{"name":"stdout","output_type":"stream","text":["53513\n","53513\n","53513\n","53513\n"]}],"source":["print(len(all_transcripts['Episodes']))\n","print(len(all_transcripts['Episode_Names']))\n","print(len(all_transcripts['Characters']))\n","print(len(all_transcripts['Lines']))"]},{"cell_type":"markdown","metadata":{"id":"SBf-w-jHIQ7k"},"source":["# Export dictionary of transcripts as CSV"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Y_d2sahCIQ7k"},"outputs":[],"source":["csv_df = pd.DataFrame(all_transcripts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"z_Nc1KunIQ7k"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.apply(lambda x: ' '.join(x.split()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fQrLCIoYIQ7l"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\s\\(.*?\\)\\s', ' ', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4DRwa3H4IQ7l"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\s\\(.*?\\)$', ' ', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uR7mtogMIQ7l"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\s\\(.*?\\)\\.\\.\\.', '', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6qETNd_fIQ7l"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\(.*?\\)', '', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RUM2G-oBIQ7l"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\(.*?$', '', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Dw8uXEQ0IQ7l"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\{.*?\\)', '', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"503oxa3DIQ7l"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'(?<=\\.).+?(?<!\\d)\\)', '', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gYlj7WdDIQ7m"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'(?<=\\?).+?\\)', '', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ufMDqbdXIQ7m"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\s\\[.*?\\]\\s', ' ', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sVlMEUcRIQ7m"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\s\\{.*?\\}\\s', ' ', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yCnLhHa3IQ7m"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\s\\[.*?$', ' ', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Egj315sdIQ7m"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\s\\{.*?\\}$', '', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NKj2S0A2IQ7m"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\s\\{.*?$', ' ', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qaxpWChDIQ7m"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.replace(r'\\[.*?\\]', '', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pu398p-2IQ7n"},"outputs":[],"source":["csv_df.Lines = csv_df.Lines.str.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GVoQo3mkIQ7n"},"outputs":[],"source":["csv_df = csv_df[~(csv_df.Lines.str.len() == 0)]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LoMaWU7nIQ7n"},"outputs":[],"source":["csv_df.Characters = csv_df.Characters.str.upper()\n","csv_df.Characters = csv_df.Characters.str.strip()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GFPfpKXRIQ7n"},"outputs":[],"source":["csv_df.Characters = csv_df.Characters.str.replace(r'^RACH$', 'RACHEL', regex=True)\n","csv_df.Characters = csv_df.Characters.str.replace(r'^MNCA$', 'MONICA', regex=True)\n","csv_df.Characters = csv_df.Characters.str.replace(r'^PHOE$', 'PHOEBE', regex=True)\n","csv_df.Characters = csv_df.Characters.str.replace(r'^CHAN$', 'CHANDLER', regex=True)\n","csv_df.Characters = csv_df.Characters.str.replace(r'^RACHE$', 'RACHEL', regex=True)\n","csv_df.Characters = csv_df.Characters.str.replace(r'^RACEL$', 'RACHEL', regex=True)\n","csv_df.Characters = csv_df.Characters.str.replace(r'^CHANDLERS$', 'CHANDLER', regex=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"D094wL_JIQ7n"},"outputs":[],"source":["csv_df.to_csv('Friends_transcripts.csv', index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pygImqssIQ7n"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.13"},"colab":{"provenance":[{"file_id":"1E-o_ib95_a0P1xnkHDX6YWV-J6O7bV09","timestamp":1669502994675}]}},"nbformat":4,"nbformat_minor":0}